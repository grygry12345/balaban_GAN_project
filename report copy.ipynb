{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN project with Ä°brahim artworks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import imageio\n",
    "import math\n",
    "from IPython import display\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and helper variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# print progress bar\n",
    "def progress(i, size, status=\"Progress\"):\n",
    "    progress = i / size * 100\n",
    "    progress = round(progress, 2)\n",
    "    print(\"\\r{}: {}%\".format(status, progress), end=\"\")\n",
    "\n",
    "# load images from \n",
    "def select_random_image(images, row, col):\n",
    "    fig, axes = plt.subplots(row, col, figsize=(row, col))\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            img = images[np.random.randint(0, len(images) - 1)]\n",
    "            axes[i, j].imshow(img / 255.0)\n",
    "            axes[i, j].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ART_DIR = \"dataset/balaban_resim_cropped\"\n",
    "\n",
    "# find number of images in the folder\n",
    "num_img = len(os.listdir(ART_DIR))\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "IMG_PATH = \"train_images\"\n",
    "\n",
    "GENERATE_RES = 2\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES\n",
    "\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "PREVIEW_ROWS = 8\n",
    "PREVIEW_COLS = 8\n",
    "PREVIEW_MARGIN = 16\n",
    "SAVE_FREQ = 2\n",
    "\n",
    "SEED_SIZE = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation Arguments (sample boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_BOOST_SIZE = num_img * 100\n",
    "ROTATION_RANGE = 20\n",
    "WIDTH_SHIFT_RANGE = 0.5\n",
    "HEIGHT_SHIFT_RANGE = 0.5\n",
    "ZOOM_RANGE = 0.3\n",
    "HORIZONTAL_FLIP = True\n",
    "VERTICAL_FLIP = False\n",
    "FILL_MODE = \"nearest\"\n",
    "BRIGHTNESS_RANGE = [0.8,1.2]\n",
    "SHEAR_RANGE = 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIAN_FILTER = False\n",
    "\n",
    "GAUSIAN_FILTER = False\n",
    "\n",
    "BILITERAL_FILTER = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "BUFFER_SIZE = 60000\n",
    "LR_RATE = 1.5e-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name of the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_img = num_img + SAMPLE_BOOST_SIZE\n",
    "\n",
    "\n",
    "brightness_range = str(BRIGHTNESS_RANGE).replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").replace(\",\", \"_\").replace(\".\", \"\")\n",
    "\n",
    "shear_range = str(SHEAR_RANGE).replace(\".\", \"\")\n",
    "\n",
    "# Name image by Arguments\n",
    "TRAIN_IMAGE_NAME = \"total_num_img_{}_fill_mode_{}_shear_range_{}_median_filter_{}_gausian_filter_{}_biliteral_filter_{}\".format(\n",
    "    total_num_img,\n",
    "    ROTATION_RANGE,\n",
    "    FILL_MODE,\n",
    "    MEDIAN_FILTER,\n",
    "    GAUSIAN_FILTER,\n",
    "    BILITERAL_FILTER,\n",
    ")\n",
    "\n",
    "lr_rate = str(LR_RATE).replace(\".\", \"\")\n",
    "\n",
    "ANIM_FILE_NAME = \"image_res_{}_preview_rows_{}_preview_cols_{}_preview_margin_{}_save_freq_{}_batch_size_{}_epochs_{}_buffer_size_{}_lr_rate_{}\".format(\n",
    "    GENERATE_RES,\n",
    "    PREVIEW_ROWS,\n",
    "    PREVIEW_COLS,\n",
    "    PREVIEW_MARGIN,\n",
    "    SAVE_FREQ,\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    BUFFER_SIZE,\n",
    "    lr_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train image name:\\n\")\n",
    "print(TRAIN_IMAGE_NAME)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Animation file name:\\n\")\n",
    "print(ANIM_FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test file name to see if it is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(ANIM_FILE_NAME+ \".txt\", \"w\") as f:\n",
    "    f.write(ANIM_FILE_NAME)\n",
    "\n",
    "os.remove(ANIM_FILE_NAME+ \".txt\")\n",
    "\n",
    "with open(TRAIN_IMAGE_NAME+ \".txt\", \"w\") as f:\n",
    "    f.write(TRAIN_IMAGE_NAME)\n",
    "\n",
    "os.remove(TRAIN_IMAGE_NAME+ \".txt\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img):\n",
    "    return cv2.medianBlur(img, ksize=3)\n",
    "\n",
    "def gausian_filter(img):\n",
    "    return cv2.GaussianBlur(img, ksize=(3, 3), sigmaX=0)\n",
    "\n",
    "def biliteral_filter(img):\n",
    "    return cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image loading, preprocessing and image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMG_PATH):\n",
    "    os.makedirs(IMG_PATH)\n",
    "\n",
    "\n",
    "if not os.path.exists(IMG_PATH + \"/images.npy\"):\n",
    "    \n",
    "    for filename in os.listdir(IMG_PATH):\n",
    "        os.remove(IMG_PATH + \"/\" + filename)\n",
    "\n",
    "    images = np.empty((0, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS))\n",
    "    for filename in os.listdir(ART_DIR):\n",
    "        \n",
    "        img = tf.keras.utils.load_img(ART_DIR + \"/\" + filename)\n",
    "        resized_img = img.resize((GENERATE_SQUARE, GENERATE_SQUARE))\n",
    "        img_array = tf.keras.utils.img_to_array(resized_img)\n",
    "\n",
    "        if MEDIAN_FILTER:\n",
    "            img_array = median_filter(img_array)\n",
    "        elif GAUSIAN_FILTER:\n",
    "            img_array = gausian_filter(img_array)\n",
    "        elif BILITERAL_FILTER:\n",
    "            img_array = biliteral_filter(img_array)\n",
    "\n",
    "        if img is not None:\n",
    "            images = np.append(images, [img_array], axis=0)\n",
    "        \n",
    "        progress(len(images), num_img, status=\"Loading images\")\n",
    "    \n",
    "\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=ROTATION_RANGE,\n",
    "        width_shift_range=WIDTH_SHIFT_RANGE,\n",
    "        height_shift_range=HEIGHT_SHIFT_RANGE,\n",
    "        horizontal_flip=HORIZONTAL_FLIP,\n",
    "        vertical_flip=VERTICAL_FLIP,\n",
    "        zoom_range=ZOOM_RANGE,\n",
    "        fill_mode=FILL_MODE,\n",
    "        brightness_range=BRIGHTNESS_RANGE,\n",
    "        shear_range=SHEAR_RANGE,\n",
    "    )\n",
    "\n",
    "\n",
    "    imageIterator = datagen.flow(np.array(images), batch_size=1)\n",
    "\n",
    "\n",
    "    for i in range(SAMPLE_BOOST_SIZE):\n",
    "        aumented_img = imageIterator.next()\n",
    "        images = np.append(images, aumented_img, axis=0)\n",
    "        \n",
    "        progress(i, SAMPLE_BOOST_SIZE, status=\"Boosting samples\")\n",
    "        \n",
    "\n",
    "    print(\"\\nNumber of images boosted:\", SAMPLE_BOOST_SIZE)\n",
    "    print(\"Number of actual images:\", num_img)\n",
    "    print(\"Number of images loaded:\", len(images))\n",
    "        \n",
    "    np.save(IMG_PATH + \"/\" + TRAIN_IMAGE_NAME + \".npy\", images)\n",
    "    print(\"Images array saved!\")\n",
    "\n",
    "else:\n",
    "    print(\"Samples already boosted!\")\n",
    "    \n",
    "    images = np.load(IMG_PATH + \"/\" +  TRAIN_IMAGE_NAME + \".npy\")\n",
    "    \n",
    "    print(\"Number of images boosted:\", SAMPLE_BOOST_SIZE)\n",
    "    print(\"Number of actual images:\", num_img)\n",
    "    print(\"Number of images loaded:\", len(images))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 64 random images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "select_random_image(images, PREVIEW_ROWS, PREVIEW_COLS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(images).reshape(-1, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
    "training_data = training_data.astype(\"float32\")\n",
    "training_data = training_data / 127.5 - 1\n",
    "\n",
    "training_data = tf.data.Dataset.from_tensor_slices(training_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channels):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(8*8*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(tf.keras.layers.Reshape((8,8,256)))\n",
    "\n",
    "    model.add(tf.keras.layers.UpSampling2D())\n",
    "    model.add(tf.keras.layers.Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "    model.add(tf.keras.layers.UpSampling2D())\n",
    "    model.add(tf.keras.layers.Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES>1:\n",
    "      model.add(tf.keras.layers.UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "      model.add(tf.keras.layers.Conv2D(64,kernel_size=3,padding=\"same\"))\n",
    "      model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "      model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(tf.keras.layers.Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(tf.keras.layers.Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create discriminator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(tf.keras.layers.ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(512, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_shape = (GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "\n",
    "discriminator.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create image save helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt,noise):\n",
    "  image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), IMAGE_CHANNELS), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "  generated_images = generator.predict(noise)\n",
    "\n",
    "  generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "  image_count = 0\n",
    "  for row in range(PREVIEW_ROWS):\n",
    "      for col in range(PREVIEW_COLS):\n",
    "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "            = generated_images[image_count] * 255\n",
    "        image_count += 1\n",
    "    \n",
    "  # save image\n",
    "  output_path = DATA_PATH\n",
    "  if not os.path.exists(output_path):\n",
    "   os.makedirs(output_path)\n",
    "\n",
    "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "  im = Image.fromarray(image_array)\n",
    "  im.save(filename)\n",
    "\n",
    "  # display image\n",
    "  plt.figure(figsize=(PREVIEW_COLS,PREVIEW_ROWS))\n",
    "  plt.imshow(image_array, interpolation='nearest', cmap='gray')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(LR_RATE,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(LR_RATE,0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training step  (Semi-automatic GradientTape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(seed, training=True)\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(\\\n",
    "        gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(\\\n",
    "        disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "    discriminator_optimizer.apply_gradients(zip(\n",
    "        gradients_of_discriminator, \n",
    "        discriminator.trainable_variables))\n",
    "  return gen_loss,disc_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  gen_losses = []\n",
    "  disc_losses = []\n",
    "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
    "                                       SEED_SIZE))\n",
    "  start = time.time()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      t = train_step(image_batch)\n",
    "      gen_loss_list.append(t[0])\n",
    "      disc_loss_list.append(t[1])\n",
    "\n",
    "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "    epoch_elapsed = time.time()-epoch_start\n",
    "    \n",
    "    \n",
    "    if (epoch+1) % SAVE_FREQ == 0 or epoch == 0:\n",
    "      # clear output\n",
    "      display.clear_output(wait=True)\n",
    "      print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "           f' {hms_string(epoch_elapsed)}')\n",
    "      save_images(epoch,fixed_seed)\n",
    "\n",
    "    # add generator loss and discriminator loss to lists\n",
    "    gen_losses.append(g_loss)\n",
    "    disc_losses.append(d_loss)\n",
    "\n",
    "\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Training time: {hms_string(elapsed)}')\n",
    "\n",
    "  return gen_losses, disc_losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images again to compare with generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_random_image(images, PREVIEW_ROWS, PREVIEW_COLS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_losses, disc_losses = train(training_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gen_losses, label='Generator Loss')\n",
    "plt.plot(disc_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GIF for training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = ANIM_FILE_NAME + '.gif'\n",
    "\n",
    "images_data = []\n",
    "# write gif frame per second (fps)\n",
    "with imageio.get_writer(anim_file, mode='I', fps=20) as writer:\n",
    "    filenames = glob.glob(DATA_PATH + '/' +'*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "display.Image(filename=anim_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "372d82335397ec2c4152a245936a15e7a3c12ebd658e8164f77465e79ac77f50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
